# ğŸ§  Legal Chatbot con FastAPI, GPT y PostgreSQL

ğŸ“„ DescripciÃ³n del Proyecto

Legal Chatbot es una soluciÃ³n conversacional desarrollada con el objetivo de brindar respuestas legales automatizadas, confiables y trazables, integrando capacidades de IA generativa (GPT) con una arquitectura robusta y escalable.

La plataforma permite a los usuarios interactuar mediante lenguaje natural, recibir respuestas fundamentadas y registrar cada conversaciÃ³n en una base de datos. EstÃ¡ diseÃ±ada para facilitar la integraciÃ³n en entornos legales, centros de ayuda, departamentos de compliance o automatizaciÃ³n de atenciÃ³n al cliente.
âœ¨ CaracterÃ­sticas destacadas

    ğŸ§  Inteligencia Artificial Legal: integraciÃ³n con OpenAI GPT (ChatCompletion) para generar respuestas legales.

    âš™ï¸ FastAPI Backend: API rÃ¡pida, escalable y con documentaciÃ³n automÃ¡tica vÃ­a Swagger.

    ğŸ” AutenticaciÃ³n segura: protecciÃ³n de endpoints mediante token Bearer.

    ğŸ—„ï¸ Persistencia de datos: conexiÃ³n a PostgreSQL para almacenar cada interacciÃ³n.

    ğŸ“ˆ Monitoreo con Prometheus: mÃ©tricas de uso y latencia listas para observabilidad avanzada.

    ğŸ³ ContenerizaciÃ³n: listo para desplegar con Docker y Docker Compose.

    â˜ï¸ Infraestructura como cÃ³digo: Terraform disponible para GCP (Cloud Run) y AWS (EC2 + RDS + ECR).

    ğŸš€ CI/CD moderno: integraciÃ³n continua con GitHub Actions y despliegue automatizado con Cloud Build.

ğŸ’¼ Casos de uso

    LegalTech y plataformas de consulta jurÃ­dica

    AutomatizaciÃ³n de soporte legal interno en empresas

    Departamentos de RRHH para resoluciÃ³n de dudas contractuales

    Agencias de cumplimiento normativo o atenciÃ³n ciudadana

---

## ğŸš€ TecnologÃ­as

- **FastAPI**: framework principal de la API.
- **OpenAI GPT**: backend de generaciÃ³n de texto.
- **PostgreSQL**: persistencia del historial de conversaciÃ³n.
- **Docker + Docker Compose**: para orquestaciÃ³n local.
- **Prometheus**: para monitoreo y mÃ©tricas.
- **Loguru**: para logging estructurado y alertas.
- **GitHub Actions**: CI/CD automÃ¡tico.
- **pytest**: testing de endpoints.
- **Terraform** (opcional): infraestructura como cÃ³digo.

---

## ğŸ§© Funcionalidades destacadas

| MÃ³dulo                   | DescripciÃ³n                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| `/chat` endpoint         | Recibe preguntas legales, aplica RAG y responde en lenguaje natural.        |
| `prompt_templates.py`    | Prompts legales por especialidad: laboral, tributario, civil, etc.          |
| `retriever.py`           | Recupera contexto legal relevante para cada pregunta.                       |
| `embedder.py`            | Indexa documentos legales y construye FAISS (o Chroma) para RAG.            |
| `auth.py`                | Verifica tokens en headers para proteger endpoints.                         |
| `db.py`                  | Guarda las preguntas/respuestas con timestamp.


## ğŸ§  Ejemplo de flujo RAG

1. El usuario envÃ­a:
   `"Â¿QuÃ© derechos tengo si me despiden por necesidades de la empresa?"`

2. El sistema busca contexto legal relevante (ej: Art. 161 del CÃ³digo del Trabajo).

3. Se genera un prompt como:

```text
ActÃºa como un abogado laboral chileno experto en el CÃ³digo del Trabajo.
Usa el siguiente contexto legal para responder con precisiÃ³n:

ArtÃ­culo 161: Despido por necesidades de la empresa...

Pregunta:
Â¿QuÃ© derechos tengo si me despiden por necesidades de la empresa?

Respuesta:
...

4. GPT responde de forma especializada y fundamentada.
```

## ğŸ“¦ InstalaciÃ³n rÃ¡pida (local)

### Requisitos

- Docker y Docker Compose
- Clave de OpenAI (`OPENAI_API_KEY`)

### Instrucciones

```bash
git clone https://github.com/tu_usuario/legal_chatbot.git
cd legal_chatbot
cp .env.example .env  # Edita con tus credenciales si lo deseas
make install
docker-compose up --build
```

Accede a la API en: [http://localhost:8000/docs](http://localhost:8000/docs)
Prometheus en: [http://localhost:9090](http://localhost:9090)

---

## ğŸ” AutenticaciÃ³n

Para consumir el endpoint `/chat`, se requiere un token tipo Bearer:

```http
Authorization: Bearer secret-token
```

Puedes modificarlo con la variable de entorno `API_TOKEN`.

---

## ğŸ§ª Testing

```bash
make test
```

---
## ğŸ”§ Uso desde terminal:

```bash
bash run.sh dev
bash run.sh int
bash run.sh prod
```

## ğŸ“ˆ Monitoreo

El endpoint `/metrics` expone estadÃ­sticas de uso para ser scrapeadas por Prometheus.

---

## â˜ï¸ Variables de entorno (.env ejemplo)

```env
OPENAI_API_KEY=tu-clave
DATABASE_URL=postgresql://user:pass@db:5432/chatbot
API_TOKEN=secret-token
```

---

## ğŸ“œ Licencia

MIT


## â˜ï¸ Despliegue con Terraform en GCP

1. Completa terraform.tfvars:

```hcl
project_id = "tu-proyecto"
region     = "us-central1"
zone       = "us-central1-a"
```

2. Ejecuta

```bash
terraform init
terraform apply -var-file="terraform.tfvars"
```

Esto crearÃ¡ una instancia con Docker y el bot en ejecuciÃ³n automÃ¡ticamente.


# ğŸ§ª Instrucciones para usar

## ğŸŒ Cloud Run + Artifact Registry (Google Cloud)

1. AutentÃ­cate en GCP:

```bash
gcloud auth application-default login
gcloud auth configure-docker
```
2. Construye la imagen:

```bash
gcloud builds submit --tag us-central1-docker.pkg.dev/legal_chatbot_project/chatbot/chatbot-image
```

3. Crea el archivo terraform.tfvars:

```hcl
project_id     = "tu-proyecto"
region         = "us-central1"
openai_api_key = "sk-..."
api_token      = "secret-token"
```

4. Inicializa y aplica Terraform:

```bash
cd terraform/cloud_run
terraform init
terraform apply -var-file="terraform.tfvars"
```

## ğŸŸ¦ EC2 + RDS + ECR (AWS completo)

### ğŸš€ Despliegue paso a paso

1. AutenticaciÃ³n

```bash
aws configure
```

2. Terraform

```bash
cd terraform/aws_deploy
terraform init
terraform apply -var 'ami_id=ami-xxxxxxxxx' -var 'key_pair_name=mi_llave'
```

3. Build y Push a ECR

```bash
# Login a ECR
aws ecr get-login-password | docker login --username AWS --password-stdin <ecr_repo_url>

# Build & push
docker build -t chatbot .
docker tag chatbot:latest <ecr_repo_url>:latest
docker push <ecr_repo_url>:latest
```

## ğŸ“ˆ Monitoreo y logs

# Dashboards de Grafana para Legal Chatbot Project

Este directorio contiene la configuraciÃ³n necesaria para que Grafana cargue automÃ¡ticamente datasources y dashboards personalizados al iniciar con Docker Compose.

## Estructura

```
grafana/
â””â”€â”€ provisioning/
    â”œâ”€â”€ datasources/
    â”‚   â””â”€â”€ prometheus.yaml
    â””â”€â”€ dashboards/
        â”œâ”€â”€ dashboard.yaml
        â””â”€â”€ mi_dashboard.json
```

- **datasources/prometheus.yaml**: Configura Prometheus como fuente de datos.
- **dashboards/dashboard.yaml**: Indica a Grafana dÃ³nde buscar dashboards.
- **dashboards/mi_dashboard.json**: Dashboard(s) exportados desde Grafana en formato JSON.

## Â¿CÃ³mo agregar un dashboard?

1. Crea o edita un dashboard en la interfaz de Grafana.
2. Exporta el dashboard como JSON.
3. Guarda el archivo exportado en `grafana/provisioning/dashboards/`.

## Â¿CÃ³mo funciona?

Al iniciar Grafana con Docker Compose, se cargarÃ¡n automÃ¡ticamente:
- El datasource de Prometheus.
- Todos los dashboards JSON ubicados en `grafana/provisioning/dashboards/`.

## Acceso

- Grafana estarÃ¡ disponible en: [http://localhost:3000](http://localhost:3000)
- Usuario/contraseÃ±a por defecto: `admin` / `admin`

## Referencias

- [DocumentaciÃ³n oficial de provisiÃ³n de Grafana](https://grafana.com/docs/grafana/latest/administration/provisioning/)


# IntegraciÃ³n de Vertex AI en Legal Chatbot Project

Esta integraciÃ³n permite consultar modelos de lenguaje alojados en Vertex AI directamente desde la API del chatbot legal e incluye integraciÃ³n con Google Cloud Monitoring (Stackdriver) y Vertex AI para trazas, mÃ©tricas y predicciones avanzadas.

## Â¿QuÃ© hace esta integraciÃ³n?

- Expone un endpoint `/vertexai-legal-answer` en la API.
- Permite enviar preguntas legales y obtener respuestas generadas por un modelo desplegado en Vertex AI.
- Facilita la conexiÃ³n segura usando credenciales de Google Cloud.

## Archivos relevantes

- `app/vertex_ai_router.py`: Contiene el router y la lÃ³gica para consultar Vertex AI.
- `app/main.py`: Incluye el router de Vertex AI en la aplicaciÃ³n FastAPI.

## ConfiguraciÃ³n

1. **Credenciales de Google Cloud**
   - Descarga una cuenta de servicio con permisos de Vertex AI.
   - Guarda el archivo JSON en una ruta segura.

2. **Variables de entorno**
   Puedes definir estas variables en tu entorno o en un archivo `.env`:
   ```
   GCP_PROJECT_ID=tu-proyecto
   VERTEX_PROJECT_ID=tu-proyecto
   VERTEX_LOCATION=us-central1
   VERTEX_ENDPOINT_ID=tu-endpoint-id
   VERTEX_CREDENTIALS_PATH=/ruta/a/credenciales.json
   ```

3. **Instala dependencias**
   ```
   pip install google-cloud-aiplatform
   ```
   Si tienes problemas con las versiones de las dependencias, puedes instalar las siguientes dependencias especÃ­ficas:
   ```
   pip install google-cloud-aiplatform==1.11.0 google-auth==1.24.0 google-auth-oauthlib==0.4.1 google-auth-httplib2==0.0.3 google-api-python-client==1.12.7
   ```
   ```
   pip install google-cloud-aiplatform opentelemetry-sdk opentelemetry-exporter-google-cloud opentelemetry-instrumentation-fastapi
   ```
Para evitar conflictos de versiones, instala las siguientes dependencias especÃ­ficas:

```
pip install opentelemetry-sdk==0.17b0 opentelemetry-api==0.17b0 opentelemetry-exporter-google-cloud==0.17b0 opentelemetry-instrumentation-fastapi
```
## Uso

Haz una peticiÃ³n POST al endpoint `/vertexai-legal-answer` con el parÃ¡metro `question`:

```
POST /vertexai-legal-answer
Content-Type: application/json

{
  "question": "Â¿CuÃ¡l es la ley de propiedad intelectual en mi paÃ­s?"
}
```

**Respuesta:**
```json
{
  "answer": "Respuesta generada por el modelo de Vertex AI."
}
```
## Notas

- AsegÃºrate de que tu endpoint de Vertex AI estÃ© desplegado y accesible.
- Puedes adaptar el endpoint para recibir otros parÃ¡metros segÃºn tu modelo.
- Consulta la [documentaciÃ³n oficial de Vertex AI](https://cloud.google.com/vertex-ai/docs) para mÃ¡s detalles sobre


# IntegraciÃ³n de Google Cloud Monitoring y Vertex AI en Legal Chatbot Project

Este proyecto ahora incluye integraciÃ³n con Google Cloud Monitoring (Stackdriver) y Vertex AI para trazas, mÃ©tricas y predicciones avanzadas.

## Funcionalidades agregadas

1. **Google Cloud Monitoring**:
   - Exporta mÃ©tricas y trazas de la aplicaciÃ³n a GCP Monitoring y Cloud Trace.
   - Usa OpenTelemetry para instrumentar la aplicaciÃ³n FastAPI.

2. **Vertex AI**:
   - Endpoint `/vertexai-legal-answer` que consulta modelos de lenguaje alojados en Vertex AI.
   - Permite enviar preguntas legales y obtener respuestas generadas por modelos personalizados.

---

## Archivos relevantes

### GCP Monitoring
- `app/gcp_monitoring.py`: Configura la exportaciÃ³n de mÃ©tricas y trazas a GCP Monitoring.
- `main.py`: Inicializa GCP Monitoring en el evento de startup.

### Vertex AI
- `app/vertex_ai_router.py`: Contiene el router y la lÃ³gica para consultar Vertex AI.
- `main.py`: Incluye el router de Vertex AI en la aplicaciÃ³n FastAPI.

---
### MÃ©tricas y trazas
- Las mÃ©tricas y trazas estarÃ¡n disponibles en la consola de GCP:
  - **Monitoring**: [https://console.cloud.google.com/monitoring](https://console.cloud.google.com/monitoring)
  - **Trace**: [https://console.cloud.google.com/traces](https://console.cloud.google.com/traces)

## Referencias

- [Google Cloud Monitoring](https://cloud.google.com/monitoring/docs)
- [Vertex AI](https://cloud.google.com/vertex-ai/docs)
- [OpenTelemetry](https://opentelemetry.io/docs/)

## ğŸ§  CrÃ©ditos

Este proyecto estÃ¡ desarrollado por JosÃ© Poblete M. y Chatgpt 4o, para profesionales del derecho y tecnologÃ­a, con foco en acceso justo a la informaciÃ³n legal automatizada.
